{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598570965670",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭      품종\n0   5.1  3.5    1.4   0.2  setosa\n1   4.9  3.0    1.4   0.2  setosa\n2   4.7  3.2    1.3   0.2  setosa\n3   4.6  3.1    1.5   0.2  setosa\n4   5.0  3.6    1.4   0.2  setosa",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>꽃잎길이</th>\n      <th>꽃잎폭</th>\n      <th>꽃받침길이</th>\n      <th>꽃받침폭</th>\n      <th>품종</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "path = './iris.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭  품종_setosa  품종_versicolor  품종_virginica\n0   5.1  3.5    1.4   0.2          1              0             0\n1   4.9  3.0    1.4   0.2          1              0             0\n2   4.7  3.2    1.3   0.2          1              0             0\n3   4.6  3.1    1.5   0.2          1              0             0\n4   5.0  3.6    1.4   0.2          1              0             0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>꽃잎길이</th>\n      <th>꽃잎폭</th>\n      <th>꽃받침길이</th>\n      <th>꽃받침폭</th>\n      <th>품종_setosa</th>\n      <th>품종_versicolor</th>\n      <th>품종_virginica</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "encode = pd.get_dummies(data)\n",
    "encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n       '품종_virginica'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "print(encode.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(150, 4) (150, 3)\n"
    }
   ],
   "source": [
    "독립=encode[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
    "종속=encode[['품종_setosa', '품종_versicolor','품종_virginica']]\n",
    "print(독립.shape, 종속.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.layers.Input(shape=[4])\n",
    "Y = tf.keras.layers.Dense(3, activation='softmax')(X)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8733\nEpoch 2/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8933\nEpoch 3/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8867\nEpoch 4/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8800\nEpoch 5/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8867\nEpoch 6/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.9067\nEpoch 7/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8933\nEpoch 8/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.9067\nEpoch 9/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8867\nEpoch 10/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.9000\nEpoch 11/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.9000\nEpoch 12/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.9000\nEpoch 13/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.9067\nEpoch 14/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8800\nEpoch 15/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.9067\nEpoch 16/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.9133\nEpoch 17/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.9067\nEpoch 18/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8933\nEpoch 19/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.9067\nEpoch 20/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.9000\nEpoch 21/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.9067\nEpoch 22/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.9133\nEpoch 23/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.9133\nEpoch 24/100\n5/5 [==============================] - 0s 998us/step - loss: 0.3994 - accuracy: 0.9067\nEpoch 25/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.9000\nEpoch 26/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.9000\nEpoch 27/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8933\nEpoch 28/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8933\nEpoch 29/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3952 - accuracy: 0.9133\nEpoch 30/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.9067\nEpoch 31/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.9133\nEpoch 32/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.9133\nEpoch 33/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.9133\nEpoch 34/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.9133\nEpoch 35/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.9200\nEpoch 36/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.9200\nEpoch 37/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.9067\nEpoch 38/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.9067\nEpoch 39/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.9067\nEpoch 40/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.9067\nEpoch 41/100\n5/5 [==============================] - 0s 998us/step - loss: 0.3863 - accuracy: 0.9067\nEpoch 42/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.9067\nEpoch 43/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.9067\nEpoch 44/100\n5/5 [==============================] - 0s 997us/step - loss: 0.3847 - accuracy: 0.9200\nEpoch 45/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.9200\nEpoch 46/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.9067\nEpoch 47/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.9067\nEpoch 48/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.9133\nEpoch 49/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.9067\nEpoch 50/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.9133\nEpoch 51/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.9067\nEpoch 52/100\n1/5 [=====>........................] - ETA: 0s - loss: 0.3621 - accuracy: 0.965/5 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.9200\nEpoch 53/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.9133\nEpoch 54/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.9133\nEpoch 55/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.9133\nEpoch 56/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.9133\nEpoch 57/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.9200\nEpoch 58/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.9267\nEpoch 59/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.9067\nEpoch 60/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.9133\nEpoch 61/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.9200\nEpoch 62/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.9133\nEpoch 63/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.9200\nEpoch 64/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.9200\nEpoch 65/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.9267\nEpoch 66/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.9067\nEpoch 67/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.9133\nEpoch 68/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.9200\nEpoch 69/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.9267\nEpoch 70/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.9200\nEpoch 71/100\n1/5 [=====>........................] - ETA: 0s - loss: 0.3565 - accuracy: 1.005/5 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.9267\nEpoch 72/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.9133\nEpoch 73/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.9267\nEpoch 74/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.9200\nEpoch 75/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.9200\nEpoch 76/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.9333\nEpoch 77/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.9200\nEpoch 78/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.9267\nEpoch 79/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.9267\nEpoch 80/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.9267\nEpoch 81/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.9333\nEpoch 82/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.9267\nEpoch 83/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.9267\nEpoch 84/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.9267\nEpoch 85/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.9267\nEpoch 86/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.9267\nEpoch 87/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.9200\nEpoch 88/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.9200\nEpoch 89/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.9267\nEpoch 90/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.9267\nEpoch 91/100\n1/5 [=====>........................] - ETA: 0s - loss: 0.3556 - accuracy: 1.005/5 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.9267\nEpoch 92/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.9333\nEpoch 93/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.9267\nEpoch 94/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.9333\nEpoch 95/100\n5/5 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.9333\nEpoch 96/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.9333\nEpoch 97/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.9267\nEpoch 98/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.9400\nEpoch 99/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.9267\nEpoch 100/100\n5/5 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.9333\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x20d6d7dbbb0>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.fit(독립, 종속, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.1540109e-04, 2.3573780e-01, 7.6344675e-01],\n       [1.0819762e-03, 2.6059565e-01, 7.3832238e-01],\n       [1.2436148e-03, 3.5156909e-01, 6.4718729e-01],\n       [5.0085247e-04, 3.8649571e-01, 6.1300343e-01],\n       [1.2339046e-03, 4.8047066e-01, 5.1829547e-01]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.predict(독립[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "품종_setosa  품종_versicolor  품종_virginica\n145          0              0             1\n146          0              0             1\n147          0              0             1\n148          0              0             1\n149          0              0             1\n"
    }
   ],
   "source": [
    "print(종속[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array([[ 0.58722   , -0.6652638 , -0.3105171 ],\n        [ 0.9533764 ,  0.5954274 , -0.70735276],\n        [-1.7302039 ,  0.7633219 ,  0.6863822 ],\n        [-2.2725997 , -1.3629049 ,  0.28357628]], dtype=float32),\n array([ 0.3352105 ,  0.40886313, -0.27129593], dtype=float32)]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}